{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11281612,"sourceType":"datasetVersion","datasetId":7053342}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Function to load and display basic dataset information\ndef load_and_explore_data(file_path):\n    \"\"\"\n    Load the dataset and perform initial exploration\n    \"\"\"\n    print(f\"Loading data from {file_path}...\")\n    df = pd.read_csv(file_path)\n    \n    print(f\"\\nDataset shape: {df.shape}\")\n    print(f\"Number of columns: {len(df.columns)}\")\n    \n    # Sample data\n    print(\"\\nSample data (first 5 rows):\")\n    print(df.head())\n    \n    # Data types\n    print(\"\\nData types:\")\n    print(df.dtypes.value_counts())\n    \n    # Check for missing values\n    missing_values = df.isnull().sum()\n    missing_percent = (missing_values / len(df)) * 100\n    missing_data = pd.DataFrame({\n        'Missing Values': missing_values,\n        'Percentage': missing_percent\n    })\n    print(\"\\nTop 20 columns with missing values:\")\n    print(missing_data[missing_data['Missing Values'] > 0].sort_values('Missing Values', ascending=False).head(20))\n    \n    return df\n\n# Function to convert date/timestamp columns\ndef convert_date_columns(df):\n    \"\"\"\n    Convert date and timestamp columns to proper datetime format\n    \"\"\"\n    print(\"\\nConverting date columns...\")\n    # Identify potential date columns (by name or data type)\n    date_columns = [col for col in df.columns if 'Date' in col or 'Time' in col or 'Timestamp' in col]\n    \n    for col in date_columns:\n        if col in df.columns:\n            try:\n                df[col] = pd.to_datetime(df[col])\n                print(f\"Converted {col} to datetime\")\n            except Exception as e:\n                print(f\"Could not convert {col} to datetime: {e}\")\n    \n    return df\n\n# Function to analyze numerical distributions\ndef analyze_numerical_columns(df):\n    \"\"\"\n    Analyze the distribution of numerical columns\n    \"\"\"\n    print(\"\\nAnalyzing numerical columns...\")\n    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n    \n    # Basic statistics\n    print(\"\\nBasic statistics for numerical columns:\")\n    print(df[numerical_cols].describe().T)\n    \n    # Create distribution plots for key financial columns\n    financial_cols = ['Price', 'Qty_', 'Sub_Total', 'Discount', 'Tax', 'Final_Total']\n    financial_cols = [col for col in financial_cols if col in numerical_cols]\n    \n    if financial_cols:\n        fig, axes = plt.subplots(len(financial_cols), 2, figsize=(15, 4*len(financial_cols)))\n        \n        for i, col in enumerate(financial_cols):\n            # Histogram\n            sns.histplot(df[col].dropna(), ax=axes[i, 0])\n            axes[i, 0].set_title(f'Distribution of {col}')\n            axes[i, 0].set_xlabel(col)\n            \n            # Box plot\n            sns.boxplot(x=df[col].dropna(), ax=axes[i, 1])\n            axes[i, 1].set_title(f'Boxplot of {col}')\n            axes[i, 1].set_xlabel(col)\n        \n        plt.tight_layout()\n        plt.savefig('numerical_distributions.png')\n        plt.close()\n        print(\"Saved distribution plots to 'numerical_distributions.png'\")\n    \n    return numerical_cols\n\n# Function to analyze categorical columns\ndef analyze_categorical_columns(df):\n    \"\"\"\n    Analyze categorical columns distributions\n    \"\"\"\n    print(\"\\nAnalyzing categorical columns...\")\n    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n    \n    # Value counts for selected categorical columns\n    important_cat_cols = ['Status', 'Payment_Type', 'Order_Type', 'Area']\n    important_cat_cols = [col for col in important_cat_cols if col in categorical_cols]\n    \n    for col in important_cat_cols:\n        print(f\"\\nValue counts for {col}:\")\n        counts = df[col].value_counts()\n        print(counts.head(10))  # Show top 10 values\n        \n        # Create bar plots\n        plt.figure(figsize=(10, 6))\n        counts.head(10).plot(kind='bar')\n        plt.title(f'Top 10 values for {col}')\n        plt.xlabel(col)\n        plt.ylabel('Count')\n        plt.tight_layout()\n        plt.savefig(f'{col}_distribution.png')\n        plt.close()\n        print(f\"Saved {col} distribution to '{col}_distribution.png'\")\n    \n    return categorical_cols\n\n# Function to check for data consistency\ndef check_data_consistency(df):\n    \"\"\"\n    Check for data consistency across related fields\n    \"\"\"\n    print(\"\\nChecking data consistency...\")\n    \n    # Check if subtotal matches price * quantity\n    if all(col in df.columns for col in ['Price', 'Qty_', 'Sub_Total']):\n        df['calculated_subtotal'] = df['Price'] * df['Qty_']\n        df['subtotal_diff'] = np.abs(df['calculated_subtotal'] - df['Sub_Total'])\n        subtotal_mismatch = df[df['subtotal_diff'] > 0.01]\n        \n        print(f\"Records with Price * Qty ≠ Sub_Total: {len(subtotal_mismatch)} ({len(subtotal_mismatch)/len(df)*100:.2f}%)\")\n        if len(subtotal_mismatch) > 0:\n            print(\"Sample mismatches:\")\n            print(subtotal_mismatch[['Price', 'Qty_', 'calculated_subtotal', 'Sub_Total', 'subtotal_diff']].head())\n    \n    # Check if final total matches subtotal - discount + tax\n    if all(col in df.columns for col in ['Sub_Total', 'Discount', 'Tax', 'Final_Total']):\n        df['calculated_final'] = df['Sub_Total'] - df['Discount'] + df['Tax']\n        df['final_diff'] = np.abs(df['calculated_final'] - df['Final_Total'])\n        final_mismatch = df[df['final_diff'] > 0.01]\n        \n        print(f\"Records with Sub_Total - Discount + Tax ≠ Final_Total: {len(final_mismatch)} ({len(final_mismatch)/len(df)*100:.2f}%)\")\n        if len(final_mismatch) > 0:\n            print(\"Sample mismatches:\")\n            print(final_mismatch[['Sub_Total', 'Discount', 'Tax', 'calculated_final', 'Final_Total', 'final_diff']].head())\n    \n    # Check tax calculation consistency\n    if all(col in df.columns for col in ['CGST_Amount', 'SGST_Amount', 'Tax']):\n        df['calculated_tax'] = df['CGST_Amount'] + df['SGST_Amount']\n        if 'VAT_Amount' in df.columns:\n            df['calculated_tax'] += df['VAT_Amount']\n        if 'Service_Charge_Amount' in df.columns:\n            df['calculated_tax'] += df['Service_Charge_Amount']\n        \n        df['tax_diff'] = np.abs(df['calculated_tax'] - df['Tax'])\n        tax_mismatch = df[df['tax_diff'] > 0.01]\n        \n        print(f\"Records with tax component sum ≠ Tax: {len(tax_mismatch)} ({len(tax_mismatch)/len(df)*100:.2f}%)\")\n        if len(tax_mismatch) > 0:\n            print(\"Sample mismatches:\")\n            print(tax_mismatch[['CGST_Amount', 'SGST_Amount', 'calculated_tax', 'Tax', 'tax_diff']].head())\n    \n    # Compare status fields across systems\n    if all(col in df.columns for col in ['Status', 'Status_z']):\n        status_z_mismatch = df[(~df['Status_z'].isna()) & (df['Status'] != df['Status_z'])]\n        print(f\"Records with Status ≠ Status_z: {len(status_z_mismatch)} ({len(status_z_mismatch)/len(df)*100:.2f}%)\")\n    \n    if all(col in df.columns for col in ['Status', 'Status_s']):\n        status_s_mismatch = df[(~df['Status_s'].isna()) & (df['Status'] != df['Status_s'])]\n        print(f\"Records with Status ≠ Status_s: {len(status_s_mismatch)} ({len(status_s_mismatch)/len(df)*100:.2f}%)\")\n    \n    # Check for invoice modifications\n    if all(col in df.columns for col in ['amount_from', 'amount_to']):\n        modified_invoices = df[(~df['amount_from'].isna()) & (~df['amount_to'].isna())]\n        print(f\"Modified invoices: {len(modified_invoices)} ({len(modified_invoices)/len(df)*100:.2f}%)\")\n        \n        if len(modified_invoices) > 0:\n            df.loc[modified_invoices.index, 'modification_amount'] = df.loc[modified_invoices.index, 'amount_to'] - df.loc[modified_invoices.index, 'amount_from']\n            print(\"Modification amount statistics:\")\n            print(df.loc[modified_invoices.index, 'modification_amount'].describe())\n    \n    return df\n\n# Function for feature engineering\ndef engineer_features(df):\n    \"\"\"\n    Create derived features that might help detect anomalies\n    \"\"\"\n    print(\"\\nEngineering features...\")\n    \n    # Financial calculation features\n    if all(col in df.columns for col in ['Price', 'Qty_', 'Sub_Total']):\n        df['price_qty_match'] = np.isclose(df['Price'] * df['Qty_'], df['Sub_Total'], rtol=0.01)\n        print(f\"Records with price * quantity matching subtotal: {df['price_qty_match'].sum()} ({df['price_qty_match'].mean()*100:.2f}%)\")\n    \n    if all(col in df.columns for col in ['Sub_Total', 'Discount', 'Tax', 'Final_Total']):\n        df['formula_match'] = np.isclose(df['Sub_Total'] - df['Discount'] + df['Tax'], df['Final_Total'], rtol=0.01)\n        print(f\"Records with subtotal - discount + tax matching final total: {df['formula_match'].sum()} ({df['formula_match'].mean()*100:.2f}%)\")\n    \n    # Tax calculation features\n    tax_components = ['CGST_Amount', 'SGST_Amount', 'VAT_Amount', 'Service_Charge_Amount']\n    available_components = [col for col in tax_components if col in df.columns]\n    \n    if available_components and 'Tax' in df.columns:\n        df['calculated_tax'] = df[available_components].sum(axis=1)\n        df['tax_matches'] = np.isclose(df['calculated_tax'], df['Tax'], rtol=0.01)\n        print(f\"Records with tax components matching total tax: {df['tax_matches'].sum()} ({df['tax_matches'].mean()*100:.2f}%)\")\n    \n    # Discount percentage feature\n    if all(col in df.columns for col in ['Discount', 'Sub_Total']):\n        df['discount_percentage'] = (df['Discount'] / df['Sub_Total']) * 100\n        df.loc[df['Sub_Total'] == 0, 'discount_percentage'] = 0\n        print(\"Discount percentage statistics:\")\n        print(df['discount_percentage'].describe())\n        \n        # Flag high discounts\n        df['high_discount'] = df['discount_percentage'] > 50\n        print(f\"Records with discount > 50%: {df['high_discount'].sum()} ({df['high_discount'].mean()*100:.2f}%)\")\n    \n    # Invoice modification features\n    if all(col in df.columns for col in ['amount_from', 'amount_to']):\n        df['invoice_modified'] = (~df['amount_from'].isna()) & (~df['amount_to'].isna())\n        df.loc[df['invoice_modified'], 'modification_amount'] = df.loc[df['invoice_modified'], 'amount_to'] - df.loc[df['invoice_modified'], 'amount_from']\n        df.loc[df['invoice_modified'], 'modification_percentage'] = (df.loc[df['invoice_modified'], 'modification_amount'] / df.loc[df['invoice_modified'], 'amount_from']) * 100\n        \n        # Flag significant reductions\n        df['significant_reduction'] = (df['invoice_modified']) & (df['modification_amount'] < -10)\n        print(f\"Records with significant price reduction (>10): {df['significant_reduction'].sum()}\")\n    \n    # Timing-related features\n    time_pairs = []\n    if all(col in df.columns for col in ['Received_Time_z', 'Delivered_Time_z']):\n        time_pairs.append(('Received_Time_z', 'Delivered_Time_z', 'zomato_delivery_minutes'))\n    \n    if all(col in df.columns for col in ['Received_Time_s', 'Delivered_Time_s']):\n        time_pairs.append(('Received_Time_s', 'Delivered_Time_s', 'swiggy_delivery_minutes'))\n    \n    for start_col, end_col, result_col in time_pairs:\n        # Calculate time difference in minutes\n        valid_times = (~df[start_col].isna()) & (~df[end_col].isna())\n        if valid_times.sum() > 0:\n            df.loc[valid_times, result_col] = (df.loc[valid_times, end_col] - df.loc[valid_times, start_col]).dt.total_seconds() / 60\n            print(f\"{result_col} statistics:\")\n            print(df.loc[valid_times, result_col].describe())\n            \n            # Flag unrealistic timing\n            df[f'{result_col}_suspicious'] = (df[result_col] < 10) | (df[result_col] > 120)\n            suspicious_count = df[f'{result_col}_suspicious'].sum()\n            print(f\"Records with suspicious {result_col} (< 10 min or > 120 min): {suspicious_count}\")\n    \n    # Status inconsistency features\n    if all(col in df.columns for col in ['Status', 'Status_z']):\n        df['status_z_mismatch'] = (~df['Status_z'].isna()) & (df['Status'] != df['Status_z'])\n        mismatch_count = df['status_z_mismatch'].sum()\n        print(f\"Status vs Status_z mismatches: {mismatch_count}\")\n    \n    if all(col in df.columns for col in ['Status', 'Status_s']):\n        df['status_s_mismatch'] = (~df['Status_s'].isna()) & (df['Status'] != df['Status_s'])\n        mismatch_count = df['status_s_mismatch'].sum()\n        print(f\"Status vs Status_s mismatches: {mismatch_count}\")\n    \n    # Cancelled with charges feature\n    if 'Status' in df.columns and 'Final_Total' in df.columns:\n        df['cancelled_with_charges'] = (df['Status'] == 'Cancelled') & (df['Final_Total'] > 0)\n        cancelled_count = df['cancelled_with_charges'].sum()\n        print(f\"Cancelled orders with charges: {cancelled_count}\")\n    \n    return df\n\n# Function to identify potential anomalies using basic rules\ndef identify_basic_anomalies(df):\n    \"\"\"\n    Identify potential anomalies using basic rule-based detection\n    \"\"\"\n    print(\"\\nIdentifying potential anomalies using basic rules...\")\n    \n    anomaly_flags = []\n    \n    # Define anomaly conditions\n    if 'price_qty_match' in df.columns:\n        anomaly_flags.append(('price_qty_mismatch', ~df['price_qty_match']))\n    \n    if 'formula_match' in df.columns:\n        anomaly_flags.append(('total_calculation_error', ~df['formula_match']))\n    \n    if 'tax_matches' in df.columns:\n        anomaly_flags.append(('tax_calculation_error', ~df['tax_matches']))\n    \n    if 'high_discount' in df.columns:\n        anomaly_flags.append(('high_discount', df['high_discount']))\n    \n    if 'significant_reduction' in df.columns:\n        anomaly_flags.append(('significant_price_reduction', df['significant_reduction']))\n    \n    time_columns = [col for col in df.columns if col.endswith('_suspicious')]\n    for col in time_columns:\n        anomaly_flags.append((col.replace('_suspicious', '_anomaly'), df[col]))\n    \n    if 'status_z_mismatch' in df.columns:\n        anomaly_flags.append(('zomato_status_mismatch', df['status_z_mismatch']))\n    \n    if 'status_s_mismatch' in df.columns:\n        anomaly_flags.append(('swiggy_status_mismatch', df['status_s_mismatch']))\n    \n    if 'cancelled_with_charges' in df.columns:\n        anomaly_flags.append(('cancelled_with_charges', df['cancelled_with_charges']))\n    \n    # Add flags to dataframe\n    for flag_name, condition in anomaly_flags:\n        df[flag_name] = condition\n        anomaly_count = condition.sum()\n        print(f\"{flag_name}: {anomaly_count} records ({anomaly_count/len(df)*100:.2f}%)\")\n    \n    # Create overall anomaly flag\n    all_flag_columns = [flag for flag, _ in anomaly_flags]\n    if all_flag_columns:\n        df['any_basic_anomaly'] = df[all_flag_columns].any(axis=1)\n        anomaly_count = df['any_basic_anomaly'].sum()\n        print(f\"\\nTotal records with at least one anomaly: {anomaly_count} ({anomaly_count/len(df)*100:.2f}%)\")\n    \n    return df\n\n# Main execution function\ndef analyze_and_preprocess_data(file_path):\n    \"\"\"\n    Main function to analyze and preprocess data\n    \"\"\"\n    # Load data\n    df = load_and_explore_data(file_path)\n    \n    # Convert date columns\n    df = convert_date_columns(df)\n    \n    # Analyze numerical columns\n    numerical_cols = analyze_numerical_columns(df)\n    \n    # Analyze categorical columns\n    categorical_cols = analyze_categorical_columns(df)\n    \n    # Check data consistency\n    df = check_data_consistency(df)\n    \n    # Engineer features\n    df = engineer_features(df)\n    \n    # Identify basic anomalies\n    df = identify_basic_anomalies(df)\n    \n    # Save processed data\n    processed_file = 'processed_data.csv'\n    df.to_csv(processed_file, index=False)\n    print(f\"\\nSaved processed data to {processed_file}\")\n    \n    # Return the processed dataframe and column info\n    return df, numerical_cols, categorical_cols\n\n# Run the analysis if executed directly\nif __name__ == \"__main__\":\n    # Replace 'hackathon_data.csv' with your actual file path\n    df, numerical_cols, categorical_cols = analyze_and_preprocess_data('/kaggle/input/hakathon/Hackathon/Hackathon Dataset.csv')\n    \n    # Print summary\n    print(\"\\n--- Data Analysis Summary ---\")\n    print(f\"Total records: {len(df)}\")\n    print(f\"Numerical columns: {len(numerical_cols)}\")\n    print(f\"Categorical columns: {len(categorical_cols)}\")\n    if 'any_basic_anomaly' in df.columns:\n        anomaly_count = df['any_basic_anomaly'].sum()\n        print(f\"Potential anomalies detected: {anomaly_count} ({anomaly_count/len(df)*100:.2f}%)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T07:22:34.230177Z","iopub.execute_input":"2025-04-05T07:22:34.230404Z","iopub.status.idle":"2025-04-05T07:23:34.592116Z","shell.execute_reply.started":"2025-04-05T07:22:34.230383Z","shell.execute_reply":"2025-04-05T07:23:34.591218Z"}},"outputs":[{"name":"stdout","text":"Loading data from /kaggle/input/hakathon/Hackathon/Hackathon Dataset.csv...\n\nDataset shape: (205888, 161)\nNumber of columns: 161\n\nSample data (first 5 rows):\n         Date                Timestamp Invoice_No_   Payment_Type Order_Type  \\\n0  13-10-2024  2024-10-13 22:42:25 UTC       11507           Cash    Dine In   \n1  04-10-2024  2024-10-04 18:53:25 UTC       C1984           Cash    Dine In   \n2  10-03-2025  2025-03-11 00:24:33 UTC       21337  Other [Paytm]    Dine In   \n3  24-08-2024  2024-08-24 15:23:25 UTC        8455           CARD    Dine In   \n4  20-01-2025  2025-01-20 22:12:29 UTC       18290           CARD    Dine In   \n\n           Area                                    Item_Name  Price  Qty_  \\\n0  Garden Table                                 Basmati Rice    375   1.0   \n1  Garden Table                  Exotic Stir Fried Vegetable    795   1.0   \n2       Dine in                                    THUMPS UP    185   1.0   \n3  Garden Table                           Manchow Soup (VEG)    365   3.0   \n4       Dine in  Assorted Stir Fried Vegetable Salt & Pepper    795   1.0   \n\n   Sub_Total  ...  Zomato_Delivery_Time  Swiggy_Delivery_Time  amount_from  \\\n0      375.0  ...                   NaN                   NaN          NaN   \n1      795.0  ...                   NaN                   NaN          NaN   \n2      185.0  ...                   NaN                   NaN          NaN   \n3     1095.0  ...                   NaN                   NaN          NaN   \n4      795.0  ...                   NaN                   NaN          NaN   \n\n  amount_to modified_by modify_comment  electron_pos bill_no invoice_no  \\\n0       NaN         NaN            NaN           NaN     NaN        NaN   \n1       NaN         NaN            NaN           NaN     NaN        NaN   \n2       NaN         NaN            NaN           NaN     NaN        NaN   \n3       NaN         NaN            NaN           NaN     NaN        NaN   \n4       NaN         NaN            NaN           NaN     NaN        NaN   \n\n   date_orap  \n0        NaN  \n1        NaN  \n2        NaN  \n3        NaN  \n4        NaN  \n\n[5 rows x 161 columns]\n\nData types:\nobject     89\nfloat64    63\nint64       9\nName: count, dtype: int64\n\nTop 20 columns with missing values:\n                            Missing Values  Percentage\nPetpooja_Identifier_z               205888  100.000000\nIdentifier_z                        205888  100.000000\nHSN                                 205888  100.000000\nReason_s                            205885   99.998543\nCancelled_Time_s                    205794   99.954344\nReason_z                            205626   99.872746\nCancelled_Time_z                    205626   99.872746\norder_cancel_reason_co              205466   99.795034\nDate_of_Anniversary_sf              205406   99.765892\nDate_of_Anniversary_ff              205402   99.763949\nCancelled_Invoice_Total_co          205385   99.755692\narea_co                             205385   99.755692\nCustomer_Email_ff                   205048   99.592011\nCustomer_Email_sf                   205047   99.591525\nDate_of_Birth_ff                    204828   99.485157\nDate_of_Birth_sf                    204825   99.483700\nSwiggy_Delivery_Time                203243   98.715321\nDelivered_Time_s                    203191   98.690065\nMark_Ready_Time_s                   203159   98.674522\nFood_Preparation_Time_S             203159   98.674522\n\nConverting date columns...\nConverted Date to datetime\nConverted Timestamp to datetime\nConverted Date_z to datetime\nConverted Invoice_Date_z to datetime\nConverted Order_Acceptance_Time_z to datetime\nConverted Order_Delivery_Time_z to datetime\nConverted Received_Time_z to datetime\nConverted Accepted_Time_z to datetime\nConverted Mark_Ready_Time_z to datetime\nConverted Rider_Arrival_Time_z to datetime\nConverted Picked_up_Time_z to datetime\nConverted Delivered_Time_z to datetime\nConverted Cancelled_Time_z to datetime\nConverted Date_s to datetime\nCould not convert Invoice_Date_s to datetime: time data \"29-12-2024\" doesn't match format \"%m-%d-%Y\", at position 4. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\nConverted Order_Acceptance_Time_s to datetime\nConverted Order_Delivery_Time_s to datetime\nConverted Received_Time_s to datetime\nConverted Accepted_Time_s to datetime\nConverted Mark_Ready_Time_s to datetime\nConverted Rider_Arrival_Time_s to datetime\nConverted Picked_up_Time_s to datetime\nConverted Delivered_Time_s to datetime\nConverted Cancelled_Time_s to datetime\nConverted Date_of_Birth_ff to datetime\nCould not convert Date_of_Anniversary_ff to datetime: time data \"22-11-2020\" doesn't match format \"%m-%d-%Y\", at position 2. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\nConverted Date_of_Birth_sf to datetime\nCould not convert Date_of_Anniversary_sf to datetime: time data \"22-11-2020\" doesn't match format \"%m-%d-%Y\", at position 2. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\nConverted First_Print_Date_BSR to datetime\nConverted Last_Settlement_Date_BSR to datetime\nConverted Food_Preparation_Time_Z to datetime\nConverted Food_Preparation_Time_S to datetime\nConverted Zomato_Delivery_Time to datetime\nConverted Swiggy_Delivery_Time to datetime\n\nAnalyzing numerical columns...\n\nBasic statistics for numerical columns:\n                               count          mean          std   min     25%  \\\nPrice                       205888.0    455.300979   454.283192   0.0   150.0   \nQty_                        205888.0      1.451165     1.496091   0.5     1.0   \nSub_Total                   205888.0    596.589558  1454.541412   0.0   185.0   \nDiscount                    205888.0      8.850193   215.217755   0.0     0.0   \nTax                         205888.0     54.685030   135.536103   0.0    13.6   \n...                              ...           ...          ...   ...     ...   \nDuration__In_Minutes_BSR    191878.0     17.964212   405.934252   0.0     3.0   \nCancelled_Invoice_Total_co     503.0   2808.701789  1620.107065  83.0  1560.0   \namount_from                   7752.0  10267.819401  9218.002615   0.0  4096.0   \namount_to                     7752.0   9704.613777  8704.697469   0.0  3855.0   \ninvoice_no                    7752.0  10374.218137  6684.093863   5.0  4571.0   \n\n                               50%      75%       max  \nPrice                        365.0    795.0   23750.0  \nQty_                           1.0      1.0     125.0  \nSub_Total                    400.0    795.0  107800.0  \nDiscount                       0.0      0.0   32250.0  \nTax                           36.5     79.6   10780.0  \n...                            ...      ...       ...  \nDuration__In_Minutes_BSR       4.0      7.0   35331.0  \nCancelled_Invoice_Total_co  2133.0   3820.0    5502.0  \namount_from                 7271.0  13699.0  137609.0  \namount_to                   6925.0  13046.0  131340.0  \ninvoice_no                  9725.0  16695.0   22500.0  \n\n[64 rows x 8 columns]\nSaved distribution plots to 'numerical_distributions.png'\n\nAnalyzing categorical columns...\n\nValue counts for Status:\nStatus\nSuccess          192544\nComplimentary     12807\nCancelled           537\nName: count, dtype: int64\nSaved Status distribution to 'Status_distribution.png'\n\nValue counts for Payment_Type:\nPayment_Type\nCARD                  74354\nCash                  68511\nOther [Paytm]         34625\nOnline                11831\nOther [AMEX]           8338\nPart Payment           5233\nOther [ZOMATO PAY]     2238\nDue Payment             758\nName: count, dtype: int64\nSaved Payment_Type distribution to 'Payment_Type_distribution.png'\n\nValue counts for Order_Type:\nOrder_Type\nDine In             189651\nDelivery(Parcel)     12596\nPick Up               3641\nName: count, dtype: int64\nSaved Order_Type distribution to 'Order_Type_distribution.png'\n\nValue counts for Area:\nArea\nDine in                  142176\nGarden Table              27211\nPersonal Dine In Room     15131\nZomato                     8739\nPARTY                      5129\nParcel                     3641\nSwiggy                     3092\nHome Delivery               765\nName: count, dtype: int64\nSaved Area distribution to 'Area_distribution.png'\n\nChecking data consistency...\nRecords with Price * Qty ≠ Sub_Total: 0 (0.00%)\nRecords with Sub_Total - Discount + Tax ≠ Final_Total: 0 (0.00%)\nRecords with tax component sum ≠ Tax: 0 (0.00%)\nRecords with Status ≠ Status_z: 7683 (3.73%)\nRecords with Status ≠ Status_s: 2700 (1.31%)\nModified invoices: 7752 (3.77%)\nModification amount statistics:\ncount    7752.000000\nmean     -563.205624\nstd       861.367244\nmin     -6804.000000\n25%      -720.000000\n50%      -365.000000\n75%      -195.000000\nmax      2985.000000\nName: modification_amount, dtype: float64\n\nEngineering features...\nRecords with price * quantity matching subtotal: 205888 (100.00%)\nRecords with subtotal - discount + tax matching final total: 205888 (100.00%)\nRecords with tax components matching total tax: 205888 (100.00%)\nDiscount percentage statistics:\ncount    205888.00000\nmean          0.73650\nstd           4.08899\nmin           0.00000\n25%           0.00000\n50%           0.00000\n75%           0.00000\nmax         100.00000\nName: discount_percentage, dtype: float64\nRecords with discount > 50%: 33 (0.02%)\nRecords with significant price reduction (>10): 7541\nzomato_delivery_minutes statistics:\ncount     7741.000000\nmean        60.877697\nstd        822.021295\nmin         11.350000\n25%         34.616667\n50%         42.000000\n75%         51.283333\nmax      41799.000000\nName: zomato_delivery_minutes, dtype: float64\nRecords with suspicious zomato_delivery_minutes (< 10 min or > 120 min): 23\nswiggy_delivery_minutes statistics:\ncount    2697.000000\nmean       43.358040\nstd        14.130539\nmin        13.383333\n25%        32.516667\n50%        41.500000\n75%        51.783333\nmax       131.716667\nName: swiggy_delivery_minutes, dtype: float64\nRecords with suspicious swiggy_delivery_minutes (< 10 min or > 120 min): 1\nStatus vs Status_z mismatches: 7683\nStatus vs Status_s mismatches: 2700\nCancelled orders with charges: 522\n\nIdentifying potential anomalies using basic rules...\nprice_qty_mismatch: 0 records (0.00%)\ntotal_calculation_error: 0 records (0.00%)\ntax_calculation_error: 0 records (0.00%)\nhigh_discount: 33 records (0.02%)\nsignificant_price_reduction: 7541 records (3.66%)\nzomato_delivery_minutes_anomaly: 23 records (0.01%)\nswiggy_delivery_minutes_anomaly: 1 records (0.00%)\nzomato_status_mismatch: 7683 records (3.73%)\nswiggy_status_mismatch: 2700 records (1.31%)\ncancelled_with_charges: 522 records (0.25%)\n\nTotal records with at least one anomaly: 18450 (8.96%)\n\nSaved processed data to processed_data.csv\n\n--- Data Analysis Summary ---\nTotal records: 205888\nNumerical columns: 64\nCategorical columns: 66\nPotential anomalies detected: 18450 (8.96%)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support, roc_auc_score\nfrom sklearn.ensemble import IsolationForest, RandomForestClassifier\nfrom sklearn.svm import OneClassSVM\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.decomposition import PCA\nimport joblib\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Function to load preprocessed data\ndef load_preprocessed_data(file_path='processed_data.csv'):\n    \"\"\"\n    Load the preprocessed data saved from the analysis phase\n    \"\"\"\n    print(\"Loading preprocessed data...\")\n    df = pd.read_csv(file_path)\n    print(f\"Loaded {len(df)} records with {len(df.columns)} features\")\n    \n    # Verify that anomaly flags are present\n    anomaly_flags = [col for col in df.columns if 'anomaly' in col or 'mismatch' in col or col == 'high_discount' or col == 'significant_price_reduction' or col == 'cancelled_with_charges']\n    print(f\"Found {len(anomaly_flags)} anomaly flag columns: {anomaly_flags}\")\n    \n    # Check for the aggregate anomaly flag\n    if 'any_basic_anomaly' in df.columns:\n        anomaly_count = df['any_basic_anomaly'].sum()\n        print(f\"Records with at least one anomaly: {anomaly_count} ({anomaly_count/len(df)*100:.2f}%)\")\n    \n    return df, anomaly_flags\n\n\n# Function to prepare features for modeling\ndef prepare_features(df):\n    \"\"\"\n    Prepare features for modeling by selecting relevant columns\n    and handling missing values\n    \"\"\"\n    print(\"\\nPreparing features for modeling...\")\n    \n    # Select numerical features relevant for anomaly detection\n    numerical_features = [\n        'Price', 'Qty_', 'Sub_Total', 'Discount', 'Tax', 'Final_Total',\n        'discount_percentage'\n    ]\n    \n    # Add calculated fields if they exist\n    optional_numericals = [\n        'modification_amount', 'zomato_delivery_minutes', 'swiggy_delivery_minutes',\n        'CGST_Amount', 'SGST_Amount', 'VAT_Amount', 'Service_Charge_Amount'\n    ]\n    \n    for col in optional_numericals:\n        if col in df.columns:\n            numerical_features.append(col)\n    \n    # Select categorical features\n    categorical_features = [\n        'Status', 'Payment_Type', 'Order_Type'\n    ]\n    \n    # Optional categorical features\n    optional_categoricals = [\n        'Area', 'Category'\n    ]\n    \n    for col in optional_categoricals:\n        if col in df.columns:\n            categorical_features.append(col)\n    \n    # Remove features with too many missing values\n    selected_features = []\n    for feature in numerical_features + categorical_features:\n        if feature in df.columns:\n            missing_pct = df[feature].isna().mean() * 100\n            if missing_pct < 30:  # Keep if less than 30% missing\n                selected_features.append(feature)\n                print(f\"Selected {feature} (missing: {missing_pct:.2f}%)\")\n            else:\n                print(f\"Dropped {feature} due to high missingness: {missing_pct:.2f}%\")\n    \n    # Create feature dataframe with selected columns\n    features_df = df[selected_features].copy()\n    \n    # Create target variable from the anomaly flags\n    if 'any_basic_anomaly' in df.columns:\n        y = df['any_basic_anomaly']\n    else:\n        anomaly_flags = [col for col in df.columns if 'anomaly' in col or 'mismatch' in col or col == 'high_discount' or col == 'significant_price_reduction' or col == 'cancelled_with_charges']\n        if anomaly_flags:\n            y = df[anomaly_flags].any(axis=1)\n        else:\n            y = None\n            print(\"Warning: No anomaly flags found, cannot create target variable\")\n    \n    # Basic preprocessing\n    numeric_cols = features_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n    categorical_cols = features_df.select_dtypes(include=['object']).columns.tolist()\n    \n    print(f\"\\nSelected {len(numeric_cols)} numeric features and {len(categorical_cols)} categorical features\")\n    print(f\"Numeric features: {numeric_cols}\")\n    print(f\"Categorical features: {categorical_cols}\")\n    \n    # Handle missing values\n    for col in numeric_cols:\n        features_df[col] = features_df[col].fillna(features_df[col].median())\n    \n    for col in categorical_cols:\n        features_df[col] = features_df[col].fillna(features_df[col].mode()[0])\n    \n    return features_df, numeric_cols, categorical_cols, y\n\n\n# Function to create preprocessor pipeline\ndef create_preprocessor(numeric_cols, categorical_cols):\n    \"\"\"\n    Create a preprocessing pipeline for numeric and categorical features\n    \"\"\"\n    numeric_transformer = Pipeline(steps=[\n        ('scaler', StandardScaler())\n    ])\n    \n    categorical_transformer = Pipeline(steps=[\n        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n    ])\n    \n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', numeric_transformer, numeric_cols),\n            ('cat', categorical_transformer, categorical_cols)\n        ]\n    )\n    \n    return preprocessor\n\n\n# Function to train and evaluate unsupervised anomaly detection models\ndef train_unsupervised_models(X, y_true=None):\n    \"\"\"\n    Train and evaluate multiple unsupervised anomaly detection models\n    \"\"\"\n    print(\"\\nTraining unsupervised anomaly detection models...\")\n    \n    # Define models to train\n    models = {\n        'Isolation Forest': IsolationForest(contamination=0.1, random_state=42),\n        'One-Class SVM': OneClassSVM(nu=0.1, gamma='scale'),\n        'Local Outlier Factor': LocalOutlierFactor(n_neighbors=20, contamination=0.1),\n        'DBSCAN': DBSCAN(eps=0.5, min_samples=5)\n    }\n    \n    results = {}\n    for name, model in models.items():\n        print(f\"\\nTraining {name}...\")\n        start_time = time.time()\n        \n        if name == 'DBSCAN':\n            y_pred = model.fit_predict(X)\n            # Convert DBSCAN labels to binary anomaly scores (-1 for anomalies, 1 for inliers)\n            y_pred = np.where(y_pred == -1, -1, 1)\n        elif name == 'Local Outlier Factor':\n            y_pred = model.fit_predict(X)\n        else:\n            y_pred = model.fit_predict(X)\n        \n        training_time = time.time() - start_time\n        \n        # For evaluation consistency, ensure -1 is anomaly and 1 is normal\n        y_pred_binary = np.where(y_pred == -1, 1, 0)  # Convert to 1 for anomaly, 0 for normal\n        \n        results[name] = {\n            'model': model,\n            'predictions': y_pred_binary,\n            'training_time': training_time\n        }\n        \n        # If true labels are provided, calculate performance metrics\n        if y_true is not None:\n            accuracy = accuracy_score(y_true, y_pred_binary)\n            precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_binary, average='binary')\n            \n            results[name].update({\n                'accuracy': accuracy,\n                'precision': precision,\n                'recall': recall,\n                'f1': f1\n            })\n            \n            print(f\"Performance of {name}:\")\n            print(f\"Accuracy: {accuracy:.4f}\")\n            print(f\"Precision: {precision:.4f}\")\n            print(f\"Recall: {recall:.4f}\")\n            print(f\"F1 Score: {f1:.4f}\")\n            print(f\"Training time: {training_time:.2f} seconds\")\n            \n            # Confusion matrix\n            cm = confusion_matrix(y_true, y_pred_binary)\n            print(\"Confusion Matrix:\")\n            print(cm)\n    \n    return results\n\n\n# Function to train and evaluate supervised model for severity classification\ndef train_supervised_model(X, y, features_df=None, severity_levels=None):\n    \"\"\"\n    Train and evaluate a supervised model for anomaly severity classification\n    \"\"\"\n    print(\"\\nTraining supervised model for anomaly severity classification...\")\n    \n    # If severity levels are not provided, use boolean classification\n    if severity_levels is None:\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, test_size=0.3, random_state=42, stratify=y\n        )\n        \n        # Train RandomForest classifier\n        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n        rf.fit(X_train, y_train)\n        \n        # Evaluate\n        y_pred = rf.predict(X_test)\n        accuracy = accuracy_score(y_test, y_pred)\n        precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n        \n        print(f\"RandomForest Classifier Performance:\")\n        print(f\"Accuracy: {accuracy:.4f}\")\n        print(f\"Precision: {precision:.4f}\")\n        print(f\"Recall: {recall:.4f}\")\n        print(f\"F1 Score: {f1:.4f}\")\n        \n        # Feature importance - FIX: Using importances without feature_names_in_\n        importances = rf.feature_importances_\n        \n        # Create feature names (since we don't have feature_names_in_)\n        if features_df is not None:\n            # Get feature names from the original dataframe\n            feature_names = features_df.columns.tolist()\n            # Ensure we don't have more importances than feature names (could happen with one-hot encoding)\n            if len(importances) > len(feature_names):\n                feature_names = [f'feature_{i}' for i in range(len(importances))]\n        else:\n            # If no features_df is provided, create generic feature names\n            feature_names = [f'feature_{i}' for i in range(len(importances))]\n            \n        # Create importance dataframe\n        feature_importance = pd.DataFrame({\n            'Feature': feature_names[:len(importances)],  # Ensure we don't exceed the length\n            'Importance': importances\n        }).sort_values('Importance', ascending=False)\n        \n        print(\"\\nTop 10 important features (estimated):\")\n        print(feature_importance.head(10))\n        \n        # Plot feature importance\n        plt.figure(figsize=(12, 8))\n        # Use only top 15 features for readability\n        top_15 = feature_importance.head(15)\n        sns.barplot(x='Importance', y='Feature', data=top_15)\n        plt.title('Feature Importance (RandomForest)')\n        plt.tight_layout()\n        plt.savefig('feature_importance.png')\n        plt.close()\n        \n        return {\n            'model': rf,\n            'feature_importance': feature_importance,\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n            'f1': f1,\n            'predictions': y_pred,\n            'test_indices': range(len(y_test))  # Simplified indices\n        }\n    else:\n        # Multi-class classification for severity levels\n        # Implementation would be similar but handling multiple classes\n        pass\n\n\n# Function to compare models\ndef compare_models(unsupervised_results, supervised_result=None):\n    \"\"\"\n    Compare model performance and generate visualizations\n    \"\"\"\n    print(\"\\nComparing model performance...\")\n    \n    # Extract performance metrics\n    model_names = []\n    accuracies = []\n    precisions = []\n    recalls = []\n    f1_scores = []\n    training_times = []\n    \n    for name, result in unsupervised_results.items():\n        if 'accuracy' in result:\n            model_names.append(name)\n            accuracies.append(result['accuracy'])\n            precisions.append(result['precision'])\n            recalls.append(result['recall'])\n            f1_scores.append(result['f1'])\n            training_times.append(result['training_time'])\n    \n    if supervised_result and 'accuracy' in supervised_result:\n        model_names.append('RandomForest (Supervised)')\n        accuracies.append(supervised_result['accuracy'])\n        precisions.append(supervised_result['precision'])\n        recalls.append(supervised_result['recall'])\n        f1_scores.append(supervised_result['f1'])\n        # If supervised_result doesn't have training_time, add a placeholder\n        if supervised_result.get('training_time'):\n            training_times.append(supervised_result['training_time'])\n        else:\n            training_times.append(0)  # Placeholder value\n    \n    # Create comparison dataframe\n    comparison_df = pd.DataFrame({\n        'Model': model_names,\n        'Accuracy': accuracies,\n        'Precision': precisions,\n        'Recall': recalls,\n        'F1 Score': f1_scores,\n        'Training Time (s)': training_times\n    })\n    \n    print(\"\\nModel Performance Comparison:\")\n    print(comparison_df)\n    \n    # Plot comparison\n    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n    plt.figure(figsize=(15, 10))\n    \n    # Create subplots\n    for i, metric in enumerate(metrics):\n        plt.subplot(2, 2, i+1)\n        bars = sns.barplot(x='Model', y=metric, data=comparison_df)\n        plt.title(f'Model Comparison - {metric}')\n        plt.xticks(rotation=45)\n        \n        # Add value labels on top of bars\n        for j, bar in enumerate(bars.patches):\n            bars.annotate(f'{comparison_df[metric].iloc[j]:.3f}',\n                         (bar.get_x() + bar.get_width() / 2, bar.get_height()),\n                         ha='center', va='bottom',\n                         fontsize=8)\n    \n    plt.tight_layout()\n    plt.savefig('model_comparison.png')\n    plt.close()\n    \n    return comparison_df\n\n\n# Function to identify and analyze anomalies\ndef analyze_anomalies(df, best_model_results, features_df, numeric_cols, categorical_cols, threshold=0.9):\n    \"\"\"\n    Analyze the anomalies detected by the best model\n    \"\"\"\n    print(\"\\nAnalyzing detected anomalies...\")\n    \n    # Get predictions from the best model\n    y_pred = best_model_results['predictions']\n    \n    # Create a DataFrame with anomalies\n    if isinstance(y_pred, np.ndarray) and len(y_pred) == len(df):\n        # If predictions match the original dataframe length\n        anomaly_indices = np.where(y_pred == 1)[0]\n        anomalies_df = df.iloc[anomaly_indices].copy()\n    else:\n        # If predictions are from a test set, we need to handle this differently\n        print(\"Warning: Predictions do not match dataframe length. Using a sample of top anomalies.\")\n        # Use any existing anomaly flags\n        anomaly_flags = [col for col in df.columns if 'anomaly' in col or 'mismatch' in col or col == 'high_discount' or col == 'significant_price_reduction' or col == 'cancelled_with_charges']\n        if 'any_basic_anomaly' in df.columns:\n            anomalies_df = df[df['any_basic_anomaly'] == 1].sample(min(1000, df['any_basic_anomaly'].sum())).copy()\n        elif anomaly_flags:\n            anomalies_df = df[df[anomaly_flags].any(axis=1)].sample(min(1000, df[anomaly_flags].any(axis=1).sum())).copy()\n        else:\n            # Fall back to a random sample\n            anomalies_df = df.sample(min(1000, len(df) // 100)).copy()\n    \n    print(f\"Total anomalies detected: {len(anomalies_df)}\")\n    \n    # Analyze anomaly types\n    anomaly_flags = [col for col in df.columns if 'anomaly' in col or 'mismatch' in col or col == 'high_discount' or col == 'significant_price_reduction' or col == 'cancelled_with_charges']\n    \n    print(\"\\nBreakdown of anomaly types:\")\n    for flag in anomaly_flags:\n        if flag in anomalies_df.columns:\n            count = anomalies_df[flag].sum()\n            pct = count / len(anomalies_df) * 100\n            print(f\"{flag}: {count} ({pct:.2f}%)\")\n    \n    # Analyze key characteristics of anomalies\n    print(\"\\nCharacteristics of anomalies:\")\n    \n    for col in numeric_cols:\n        if col in anomalies_df.columns and col in df.columns:\n            anomaly_mean = anomalies_df[col].mean()\n            normal_mean = df[~df.index.isin(anomalies_df.index)][col].mean()\n            print(f\"{col}: Anomaly mean = {anomaly_mean:.2f}, Normal mean = {normal_mean:.2f}\")\n    \n    for col in categorical_cols:\n        if col in anomalies_df.columns:\n            print(f\"\\nDistribution of {col} in anomalies:\")\n            value_counts = anomalies_df[col].value_counts().head(5)\n            print(value_counts)\n    \n    # Assign severity scores using a more meaningful approach\n    # We'll use a combination of factors to determine severity\n    \n    # 1. Check for invoice modifications (if available)\n    if 'modification_amount' in anomalies_df.columns:\n        anomalies_df['mod_severity'] = 0\n        # Higher severity for larger modifications\n        cond1 = (anomalies_df['modification_amount'] < -1000) \n        cond2 = (anomalies_df['modification_amount'] < -500) & (anomalies_df['modification_amount'] >= -1000)\n        cond3 = (anomalies_df['modification_amount'] < -100) & (anomalies_df['modification_amount'] >= -500)\n        \n        anomalies_df.loc[cond1, 'mod_severity'] = 3  # High\n        anomalies_df.loc[cond2, 'mod_severity'] = 2  # Medium\n        anomalies_df.loc[cond3, 'mod_severity'] = 1  # Low\n    else:\n        anomalies_df['mod_severity'] = 0\n    \n    # 2. Check for high discounts\n    if 'discount_percentage' in anomalies_df.columns:\n        anomalies_df['discount_severity'] = 0\n        # Higher severity for larger discounts\n        cond1 = (anomalies_df['discount_percentage'] > 50)\n        cond2 = (anomalies_df['discount_percentage'] > 30) & (anomalies_df['discount_percentage'] <= 50)\n        cond3 = (anomalies_df['discount_percentage'] > 20) & (anomalies_df['discount_percentage'] <= 30)\n        \n        anomalies_df.loc[cond1, 'discount_severity'] = 3  # High\n        anomalies_df.loc[cond2, 'discount_severity'] = 2  # Medium\n        anomalies_df.loc[cond3, 'discount_severity'] = 1  # Low\n    else:\n        anomalies_df['discount_severity'] = 0\n    \n    # 3. Check for cancelled orders with charges\n    anomalies_df['cancel_severity'] = 0\n    if 'cancelled_with_charges' in anomalies_df.columns and 'Final_Total' in anomalies_df.columns:\n        cond1 = (anomalies_df['cancelled_with_charges'] == True) & (anomalies_df['Final_Total'] > 1000)\n        cond2 = (anomalies_df['cancelled_with_charges'] == True) & (anomalies_df['Final_Total'] > 500) & (anomalies_df['Final_Total'] <= 1000)\n        cond3 = (anomalies_df['cancelled_with_charges'] == True) & (anomalies_df['Final_Total'] <= 500)\n        \n        anomalies_df.loc[cond1, 'cancel_severity'] = 3  # High\n        anomalies_df.loc[cond2, 'cancel_severity'] = 2  # Medium\n        anomalies_df.loc[cond3, 'cancel_severity'] = 1  # Low\n    \n    # 4. Check for status mismatches\n    anomalies_df['status_severity'] = 0\n    if 'status_z_mismatch' in anomalies_df.columns or 'status_s_mismatch' in anomalies_df.columns:\n        if 'status_z_mismatch' in anomalies_df.columns:\n            anomalies_df.loc[anomalies_df['status_z_mismatch'] == True, 'status_severity'] = 2\n        if 'status_s_mismatch' in anomalies_df.columns:\n            anomalies_df.loc[anomalies_df['status_s_mismatch'] == True, 'status_severity'] = 2\n    \n    # Combine all severity factors to get overall severity score\n    anomalies_df['severity_score'] = anomalies_df[['mod_severity', 'discount_severity', 'cancel_severity', 'status_severity']].max(axis=1)\n    \n    # If all are zero, assign a low severity\n    anomalies_df.loc[anomalies_df['severity_score'] == 0, 'severity_score'] = 1\n    \n    # Map to severity categories\n    severity_map = {1: 'Low', 2: 'Medium', 3: 'High'}\n    anomalies_df['severity'] = anomalies_df['severity_score'].map(severity_map)\n    \n    print(\"\\nSeverity distribution:\")\n    print(anomalies_df['severity'].value_counts())\n    \n    # Sample anomalies by severity\n    if 'High' in anomalies_df['severity'].values:\n        print(\"\\nSample high severity anomalies:\")\n        high_severity = anomalies_df[anomalies_df['severity'] == 'High'].head(5)\n        print(high_severity[['Invoice_No_', 'Status', 'Payment_Type', 'Sub_Total', 'Final_Total', 'discount_percentage']])\n    \n    # Return the anomalies with severity\n    return anomalies_df\n\n\n# Function to save trained models\ndef save_models(models_dict, filename='anomaly_detection_models.pkl'):\n    \"\"\"\n    Save trained models to a file\n    \"\"\"\n    joblib.dump(models_dict, filename)\n    print(f\"\\nSaved models to {filename}\")\n\n\n# Function to create serializable anomaly data for API\ndef create_anomaly_data_for_api(anomalies_df, schema_info=None):\n    \"\"\"\n    Create serializable data for the API\n    \"\"\"\n    print(\"\\nPreparing anomaly data for API...\")\n    \n    # If schema info is available, use it for context\n    if schema_info is None:\n        # Create a simple dictionary from the dataframe\n        anomaly_data = []\n        for idx, row in anomalies_df.iterrows():\n            item = {\n                'invoice_id': str(row.get('Invoice_No_', str(idx))),\n                'timestamp': str(row.get('Timestamp', '')),\n                'anomaly_type': 'Unknown',\n                'severity': str(row.get('severity', 'Medium')),\n                'fields': {}\n            }\n            \n            # Determine anomaly type\n            if 'tax_calculation_error' in anomalies_df.columns and row.get('tax_calculation_error'):\n                item['anomaly_type'] = 'Tax Calculation Error'\n            elif 'price_qty_mismatch' in anomalies_df.columns and row.get('price_qty_mismatch'):\n                item['anomaly_type'] = 'Price Quantity Mismatch'\n            elif 'significant_price_reduction' in anomalies_df.columns and row.get('significant_price_reduction'):\n                item['anomaly_type'] = 'Significant Price Reduction'\n            elif 'high_discount' in anomalies_df.columns and row.get('high_discount'):\n                item['anomaly_type'] = 'High Discount'\n            elif 'cancelled_with_charges' in anomalies_df.columns and row.get('cancelled_with_charges'):\n                item['anomaly_type'] = 'Cancelled with Charges'\n            elif 'zomato_status_mismatch' in anomalies_df.columns and row.get('zomato_status_mismatch'):\n                item['anomaly_type'] = 'Zomato Status Mismatch'\n            elif 'swiggy_status_mismatch' in anomalies_df.columns and row.get('swiggy_status_mismatch'):\n                item['anomaly_type'] = 'Swiggy Status Mismatch'\n            \n            # Add relevant fields\n            for col in ['Price', 'Qty_', 'Sub_Total', 'Discount', 'Tax', 'Final_Total',\n                        'Status', 'Payment_Type', 'Order_Type', 'discount_percentage']:\n                if col in row and not pd.isna(row[col]):\n                    item['fields'][col] = str(row[col])\n            \n            # Add modification details if available\n            if 'amount_from' in row and 'amount_to' in row and not pd.isna(row['amount_from']) and not pd.isna(row['amount_to']):\n                item['fields']['modified_from'] = str(row['amount_from'])\n                item['fields']['modified_to'] = str(row['amount_to'])\n                item['fields']['modification_amount'] = str(row.get('modification_amount', row['amount_to'] - row['amount_from']))\n            \n            anomaly_data.append(item)\n    else:\n        # Use schema info for more detailed context\n        # Implementation would depend on schema format\n        anomaly_data = []  # Placeholder\n    \n    print(f\"Prepared {len(anomaly_data)} anomaly records for API\")\n    return anomaly_data\n\n\n# Main execution function\ndef build_and_compare_models(processed_data_path='processed_data.csv'):\n    \"\"\"\n    Main function to build and compare anomaly detection models\n    \"\"\"\n    # Load preprocessed data\n    df, anomaly_flags = load_preprocessed_data(processed_data_path)\n    \n    # Prepare features\n    features_df, numeric_cols, categorical_cols, y = prepare_features(df)\n    \n    # Create preprocessor\n    preprocessor = create_preprocessor(numeric_cols, categorical_cols)\n    \n    # Transform data\n    print(\"\\nTransforming features...\")\n    X_transformed = preprocessor.fit_transform(features_df)\n    print(f\"Transformed data shape: {X_transformed.shape}\")\n    \n    # Apply dimensionality reduction for visualization\n    print(\"\\nApplying PCA for visualization...\")\n    pca = PCA(n_components=2)\n    X_pca = pca.fit_transform(X_transformed)\n    \n    # Plot PCA\n    plt.figure(figsize=(10, 8))\n    if y is not None:\n        plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.5)\n        plt.title('PCA Visualization of Data with Anomalies')\n    else:\n        plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.5)\n        plt.title('PCA Visualization of Data')\n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    plt.savefig('pca_visualization.png')\n    plt.close()\n    \n    # Train unsupervised models\n    unsupervised_results = train_unsupervised_models(X_transformed, y)\n    \n    # Train supervised model if target is available\n    supervised_result = None\n    if y is not None:\n        supervised_result = train_supervised_model(X_transformed, y, features_df)\n    \n    # Compare models\n    comparison_results = compare_models(unsupervised_results, supervised_result)\n    \n    # Determine best model based on F1 score\n    best_model_name = comparison_results.sort_values('F1 Score', ascending=False).iloc[0]['Model']\n    print(f\"\\nBest model based on F1 Score: {best_model_name}\")\n    \n    if best_model_name in unsupervised_results:\n        best_model_results = unsupervised_results[best_model_name]\n    else:\n        best_model_results = supervised_result\n    \n    # Analyze anomalies from the best model\n    anomalies_df = analyze_anomalies(df, best_model_results, features_df, numeric_cols, categorical_cols)\n    \n    # Save models\n    models_to_save = {\n        'preprocessor': preprocessor,\n        'unsupervised_models': {k: v['model'] for k, v in unsupervised_results.items()},\n        'supervised_model': supervised_result['model'] if supervised_result else None,\n        'numeric_cols': numeric_cols,\n        'categorical_cols': categorical_cols\n    }\n    save_models(models_to_save)\n    \n    # Create API-ready data\n    anomaly_data = create_anomaly_data_for_api(anomalies_df)\n    \n    # Save anomaly data for API\n    with open('anomaly_data_for_api.json', 'w') as f:\n        import json\n        json.dump(anomaly_data, f, default=str)\n    print(\"Saved anomaly data for API to 'anomaly_data_for_api.json'\")\n    \n    return {\n        'models': models_to_save,\n        'comparison': comparison_results,\n        'best_model': best_model_name,\n        'anomalies': anomalies_df,\n        'api_data': anomaly_data\n    }\n\n\n# Run the model building process if executed directly\nif __name__ == \"__main__\":\n    # Replace with your processed data path if different\n    results = build_and_compare_models('/kaggle/working/processed_data.csv')\n    \n    print(\"\\n--- Model Building Summary ---\")\n    print(f\"Best model: {results['best_model']}\")\n    print(f\"Total anomalies detected: {len(results['anomalies'])}\")\n    print(f\"API data prepared: {len(results['api_data'])} records\")\n    print(\"All models saved and ready for API deployment\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T07:23:34.593341Z","iopub.execute_input":"2025-04-05T07:23:34.593722Z","iopub.status.idle":"2025-04-05T08:00:09.289393Z","shell.execute_reply.started":"2025-04-05T07:23:34.593689Z","shell.execute_reply":"2025-04-05T08:00:09.288630Z"}},"outputs":[{"name":"stdout","text":"Loading preprocessed data...\nLoaded 205888 records with 192 features\nFound 11 anomaly flag columns: ['high_discount', 'status_z_mismatch', 'status_s_mismatch', 'cancelled_with_charges', 'price_qty_mismatch', 'significant_price_reduction', 'zomato_delivery_minutes_anomaly', 'swiggy_delivery_minutes_anomaly', 'zomato_status_mismatch', 'swiggy_status_mismatch', 'any_basic_anomaly']\nRecords with at least one anomaly: 18450 (8.96%)\n\nPreparing features for modeling...\nSelected Price (missing: 0.00%)\nSelected Qty_ (missing: 0.00%)\nSelected Sub_Total (missing: 0.00%)\nSelected Discount (missing: 0.00%)\nSelected Tax (missing: 0.00%)\nSelected Final_Total (missing: 0.00%)\nSelected discount_percentage (missing: 0.00%)\nDropped modification_amount due to high missingness: 96.23%\nDropped zomato_delivery_minutes due to high missingness: 96.24%\nDropped swiggy_delivery_minutes due to high missingness: 98.69%\nSelected CGST_Amount (missing: 0.00%)\nSelected SGST_Amount (missing: 0.00%)\nSelected VAT_Amount (missing: 0.00%)\nSelected Service_Charge_Amount (missing: 0.00%)\nSelected Status (missing: 0.00%)\nSelected Payment_Type (missing: 0.00%)\nSelected Order_Type (missing: 0.00%)\nSelected Area (missing: 0.00%)\nSelected Category (missing: 0.00%)\n\nSelected 11 numeric features and 5 categorical features\nNumeric features: ['Price', 'Qty_', 'Sub_Total', 'Discount', 'Tax', 'Final_Total', 'discount_percentage', 'CGST_Amount', 'SGST_Amount', 'VAT_Amount', 'Service_Charge_Amount']\nCategorical features: ['Status', 'Payment_Type', 'Order_Type', 'Area', 'Category']\n\nTransforming features...\nTransformed data shape: (205888, 84)\n\nApplying PCA for visualization...\n\nTraining unsupervised anomaly detection models...\n\nTraining Isolation Forest...\nPerformance of Isolation Forest:\nAccuracy: 0.8562\nPrecision: 0.2290\nRecall: 0.2556\nF1 Score: 0.2416\nTraining time: 15.18 seconds\nConfusion Matrix:\n[[171564  15874]\n [ 13735   4715]]\n\nTraining One-Class SVM...\nPerformance of One-Class SVM:\nAccuracy: 0.8390\nPrecision: 0.1410\nRecall: 0.1564\nF1 Score: 0.1483\nTraining time: 1893.50 seconds\nConfusion Matrix:\n[[169863  17575]\n [ 15565   2885]]\n\nTraining Local Outlier Factor...\nPerformance of Local Outlier Factor:\nAccuracy: 0.8475\nPrecision: 0.1853\nRecall: 0.2068\nF1 Score: 0.1955\nTraining time: 140.20 seconds\nConfusion Matrix:\n[[170665  16773]\n [ 14634   3816]]\n\nTraining DBSCAN...\nPerformance of DBSCAN:\nAccuracy: 0.8727\nPrecision: 0.1382\nRecall: 0.0804\nF1 Score: 0.1016\nTraining time: 110.69 seconds\nConfusion Matrix:\n[[178188   9250]\n [ 16967   1483]]\n\nTraining supervised model for anomaly severity classification...\nRandomForest Classifier Performance:\nAccuracy: 0.9831\nPrecision: 0.8899\nRecall: 0.9259\nF1 Score: 0.9076\n\nTop 10 important features (estimated):\n       Feature  Importance\n10  feature_10    0.154145\n17  feature_17    0.137200\n32  feature_32    0.096630\n23  feature_23    0.090116\n4    feature_4    0.075089\n22  feature_22    0.068365\n5    feature_5    0.047847\n0    feature_0    0.034027\n2    feature_2    0.033517\n7    feature_7    0.032717\n\nComparing model performance...\n\nModel Performance Comparison:\n                       Model  Accuracy  Precision    Recall  F1 Score  \\\n0           Isolation Forest  0.856189   0.229006  0.255556  0.241553   \n1              One-Class SVM  0.839039   0.141007  0.156369  0.148291   \n2       Local Outlier Factor  0.847456   0.185342  0.206829  0.195497   \n3                     DBSCAN  0.872664   0.138172  0.080379  0.101635   \n4  RandomForest (Supervised)  0.983098   0.889911  0.925926  0.907562   \n\n   Training Time (s)  \n0          15.175220  \n1        1893.495170  \n2         140.197848  \n3         110.686913  \n4           0.000000  \n\nBest model based on F1 Score: RandomForest (Supervised)\n\nAnalyzing detected anomalies...\nWarning: Predictions do not match dataframe length. Using a sample of top anomalies.\nTotal anomalies detected: 1000\n\nBreakdown of anomaly types:\nhigh_discount: 2 (0.20%)\nstatus_z_mismatch: 409 (40.90%)\nstatus_s_mismatch: 125 (12.50%)\ncancelled_with_charges: 29 (2.90%)\nprice_qty_mismatch: 0 (0.00%)\nsignificant_price_reduction: 436 (43.60%)\nzomato_delivery_minutes_anomaly: 2 (0.20%)\nswiggy_delivery_minutes_anomaly: 0 (0.00%)\nzomato_status_mismatch: 409 (40.90%)\nswiggy_status_mismatch: 125 (12.50%)\nany_basic_anomaly: 1000 (100.00%)\n\nCharacteristics of anomalies:\nPrice: Anomaly mean = 509.26, Normal mean = 455.04\nQty_: Anomaly mean = 1.40, Normal mean = 1.45\nSub_Total: Anomaly mean = 649.74, Normal mean = 596.33\nDiscount: Anomaly mean = 13.10, Normal mean = 8.83\nTax: Anomaly mean = 16.51, Normal mean = 54.87\nFinal_Total: Anomaly mean = 653.15, Normal mean = 642.37\ndiscount_percentage: Anomaly mean = 1.68, Normal mean = 0.73\nCGST_Amount: Anomaly mean = 6.81, Normal mean = 11.24\nSGST_Amount: Anomaly mean = 6.81, Normal mean = 11.24\nVAT_Amount: Anomaly mean = 1.94, Normal mean = 8.24\nService_Charge_Amount: Anomaly mean = 0.95, Normal mean = 24.15\n\nDistribution of Status in anomalies:\nStatus\nSuccess      971\nCancelled     29\nName: count, dtype: int64\n\nDistribution of Payment_Type in anomalies:\nPayment_Type\nOnline           555\nCash             197\nCARD             140\nOther [Paytm]     69\nPart Payment      14\nName: count, dtype: int64\n\nDistribution of Order_Type in anomalies:\nOrder_Type\nDelivery(Parcel)    555\nDine In             445\nName: count, dtype: int64\n\nDistribution of Area in anomalies:\nArea\nZomato                   422\nDine in                  337\nSwiggy                   133\nGarden Table              66\nPersonal Dine In Room     37\nName: count, dtype: int64\n\nDistribution of Category in anomalies:\nCategory\nTANDOOR BREADS             201\nINDIAN MAIN COURSE         199\nORIENTAL STARTER            98\nTANDOOR STARTER             83\nORIENTAL RICE & NOODLES     77\nName: count, dtype: int64\n\nSeverity distribution:\nseverity\nMedium    640\nLow       289\nHigh       71\nName: count, dtype: int64\n\nSample high severity anomalies:\n       Invoice_No_     Status  Payment_Type  Sub_Total  Final_Total  \\\n60304          247    Success  Part Payment     1590.0       1502.6   \n133566        4571    Success          CARD      795.0        834.8   \n106565       11351  Cancelled        Online     1530.0       1300.5   \n55600         2244    Success          Cash      300.0        283.6   \n192687       10000    Success          CARD      365.0        344.9   \n\n        discount_percentage  \n60304                  10.0  \n133566                  0.0  \n106565                 15.0  \n55600                  10.0  \n192687                 10.0  \n\nSaved models to anomaly_detection_models.pkl\n\nPreparing anomaly data for API...\nPrepared 1000 anomaly records for API\nSaved anomaly data for API to 'anomaly_data_for_api.json'\n\n--- Model Building Summary ---\nBest model: RandomForest (Supervised)\nTotal anomalies detected: 1000\nAPI data prepared: 1000 records\nAll models saved and ready for API deployment\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}